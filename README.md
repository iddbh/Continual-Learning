# Continual Learning
## 2024
* Muppidi, A., Zhang, Z. and Yang, H., 2024. [Pick up the PACE: A Parameter-Free Optimizer for Lifelong Reinforcement Learning](https://arxiv.org/abs/2405.16642)
. arXiv preprint arXiv:2405.16642. [[website](https://computationalrobotics.seas.harvard.edu/TRAC/) + [python](https://github.com/ComputationalRobotics/TRAC?tab=readme-ov-file)]
* Julian, J., Koh, Y.S. and Bifet, A., 2024, August. [Sketch-Based Replay Projection for Continual Learning](https://dl.acm.org/doi/pdf/10.1145/3637528.3671714). In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (pp. 1325-1335). [[python](https://github.com/jjul482/Sketched-Replay-Projection)]
* Wang, L., Xie, J., Zhang, X., Huang, M., Su, H. and Zhu, J., 2024. [Hierarchical decomposition of prompt-based continual learning: Rethinking obscured sub-optimality](https://proceedings.neurips.cc/paper_files/paper/2023/file/d9f8b5abc8e0926539ecbb492af7b2f1-Paper-Conference.pdf). Advances in Neural Information Processing Systems, 36. [[python](https://github.com/thu-ml/HiDe-Prompt)]
## 2023
* Abbas, Z., Zhao, R., Modayil, J., White, A. and Machado, M.C., 2023, November. [Loss of plasticity in continual deep reinforcement learning](https://www.nature.com/articles/s41586-024-07711-7). In Conference on Lifelong Learning Agents (pp. 620-636). PMLR. [[python](https://github.com/shibhansh/loss-of-plasticity)]
* Irie, K., Csord√°s, R. and Schmidhuber, J., 2023. [Automating Continual Learning](https://openreview.net/pdf?id=5twh6pM4SR).
* Mok, J., Do, J., Lee, S., Taghavi, T., Yu, S. and Yoon, S., 2023, July. [Large-scale lifelong learning of in-context instructions and how to tackle it](https://aclanthology.org/2023.acl-long.703.pdf). In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 12573-12589). [[website](https://aclanthology.org/2023.acl-long.703/)]
* Lu, P., Caprio, M., Eaton, E. and Lee, I., 2023. [IBCL: Zero-shot Model Generation for Task Trade-offs in Continual Learning](https://arxiv.org/pdf/2305.14782). arXiv preprint arXiv:2305.14782. [[python](https://github.com/ibcl-anon/ibcl)]
* Anand, N. and Precup, D., 2024. [Prediction and control in continual reinforcement learning](https://proceedings.neurips.cc/paper_files/paper/2023/file/c94bbbef466ab1b2cfa100e41413b3a8-Paper-Conference.pdf). Advances in Neural Information Processing Systems, 36.
## 2022
* Savage, N., 2022. [Learning over a lifetime](https://www.nature.com/articles/d41586-022-01962-y). Nature.
* Zhang, Y., Pfahringer, B., Frank, E., Bifet, A., Lim, N.J.S. and Jia, Y., 2022, November. [Repeated augmented rehearsal: a simple but strong baseline for online continual learning](https://papers.neurips.cc/paper_files/paper/2022/file/5ebbbac62b968254093023f1c95015d3-Paper-Conference.pdf). In Proceedings of the 36th International Conference on Neural Information Processing Systems (pp. 14771-14783).[[python](https://github.com/YaqianZhang/RepeatedAugmentedRehearsal/tree/master)]
## 2021
* Dohare, S., Sutton, R.S. and Mahmood, A.R., 2021. [Continual backprop: Stochastic gradient descent with persistent randomness](https://arxiv.org/abs/2108.06325). arXiv preprint arXiv:2108.06325. [[python](https://github.com/shibhansh/loss-of-plasticity)]
